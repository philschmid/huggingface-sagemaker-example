# -*- coding: utf-8 -*-
"""HuggingFace Sagemaker Notebook Trainer & dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o3D9dwO1ZQt8PTLIs5oNDqJ7ReKDnol9

[script example](https://github.com/huggingface/transformers/blob/9a12b9696fca52c71601b59a73c8e18426519027/examples/text-classification/run_glue.py#L295)
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install transformers datasets sklearn

# imports

from datasets import load_dataset
from transformers import AutoTokenizer,AutoModelForSequenceClassification, Trainer, TrainingArguments
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# logging

import random
import logging

logger = logging.getLogger(__name__)

# Setup logging
logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%m/%d/%Y %H:%M:%S",
  level=logging.INFO,
)

# load dataset


dataset = load_dataset('imdb')

label_list = dataset["train"].features["label"].names
num_labels = len(label_list)

model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased')

tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')

#helper tokenizer function
def tokenize(batch):
    return tokenizer(batch['text'], padding='max_length', truncation=True)

# load dataset
train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])
test_dataset = test_dataset.shuffle().select(range(10000)) # smaller the size for test dataset to 10k 

# test
train_dataset = train_dataset.shuffle().select(range(1000)) # smaller the size for test dataset to 10k 
test_dataset = test_dataset.shuffle().select(range(500)) # smaller the size for test dataset to 10k 



# tokenize dataset
train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))
test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))

# train.rename_column_("label", "labels")


# Log a few random samples from the training set:
for index in random.sample(range(len(train_dataset)), 3):
    logger.info(f"Sample {index} of the training set: {train_dataset[index]}.")

# set format for pytorch
train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])
test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=2,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    warmup_steps=500,
    weight_decay=0.01,
    evaluation_strategy='epoch',
    logging_dir='./logs',
)

trainer = Trainer(
    model=model,
    args=training_args,
    compute_metrics=compute_metrics,
    train_dataset=train_dataset,
    eval_dataset=test_dataset
)

trainer.train()

import os 

eval_result = trainer.evaluate(eval_dataset=test_dataset)

output_eval_file = os.path.join(".", f"eval_results.txt")


# writes eval result to file which can be accessed later
with open(output_eval_file, "w") as writer:
    logger.info(f"***** Eval results *****")
    for key, value in sorted(eval_result.items()):
        logger.info(f"  {key} = {value}")
        writer.write(f"{key} = {value}\n")

trainer.save_model()  # Saves the model



"""# Custom Training Script"""

from torch.utils.data import DataLoader
from transformers import AdamW
import torch

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased')

model.to(device)
model.train()

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

optim = AdamW(model.parameters(), lr=5e-5)

for epoch in range(3):
    for batch in train_loader:
        optim.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs[0]
        loss.backward()
        optim.step()

model.eval()

from tqdm import tqdm
import numpy as np
 # Eval!

def compute_metrics(preds, labels):
  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
  acc = accuracy_score(labels, preds)
  return {
      'accuracy': acc,
      'f1': f1,
      'precision': precision,
      'recall': recall
  }

logger.info("***** Running evaluation *****")
logger.info("  Num examples = %d", len(test_dataset))

eval_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)

eval_loss = 0.0
nb_eval_steps = 0
preds = None
out_label_ids = None
for batch in tqdm(eval_dataloader, desc="Evaluating"):
    model.eval()

    with torch.no_grad():
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        tmp_eval_loss, logits = outputs[:2]

        eval_loss += tmp_eval_loss.mean().item()
    nb_eval_steps += 1
    if preds is None:
        preds = logits.detach().cpu().numpy()
        out_label_ids = labels.detach().cpu().numpy()
    else:
        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)
        out_label_ids = np.append(out_label_ids, labels.detach().cpu().numpy(), axis=0)

eval_loss = eval_loss / nb_eval_steps
preds = np.argmax(preds, axis=1)
result = compute_metrics(preds, out_label_ids)

output_eval_file = os.path.join(".", "eval_man_results.txt")
with open(output_eval_file, "w") as writer:
    logger.info("***** Eval results  *****")
    for key in sorted(result.keys()):
        logger.info("  %s = %s", key, str(result[key]))
        writer.write("%s = %s\n" % (key, str(result[key])))

