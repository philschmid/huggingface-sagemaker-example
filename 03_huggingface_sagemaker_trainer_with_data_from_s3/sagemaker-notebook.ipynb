{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker example using `Trainer` class\n",
    "\n",
    "Each folder starting with `0X_..` contains an specific sagemaker example. Each example contains a jupyter notebooke `sagemaker-example.ipynb` and a `src/` folder. The `sagemaker-example` is a jupyter notebook which is used to train transformers i ncombination with datasets on AWS Sagemaker. The `src/` folder contains the `train.py`, our training script and `requirements.txt` for additional dependencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Sagemaker Session with local AWS Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From outside these notebooks, `get_execution_role()` will return an exception because it does not know what is the role name that SageMaker requires.\n",
    "\n",
    "To solve this issue, pass the IAM role name instead of using `get_execution_role()`.\n",
    "\n",
    "Therefore you have to create an IAM-Role with correct permission for sagemaker to start training jobs and download files from s3. Beware that you need s3 permission on bucket-level `\"arn:aws:s3:::sagemaker-*\"` and on object-level     `\"arn:aws:s3:::sagemaker-*/*\"`. \n",
    "\n",
    "You can read [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) how to create a role with right permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local aws profile configured in ~/.aws/credentials\n",
    "local_profile_name='hf-sm' # optional if you only have default configured\n",
    "\n",
    "# role name for sagemaker -> needs the described permissions from above\n",
    "role_name = \"SageMakerRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name philipp to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::558105141721:role/SageMakerRole\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "try:\n",
    "    sess = sagemaker.Session()\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    import boto3\n",
    "    # creates a boto3 session using the local profile we defined\n",
    "    if local_profile_name:\n",
    "        bt3 = boto3.session.Session(profile_name=local_profile_name)\n",
    "        iam = bt3.client('iam')\n",
    "        # create sagemaker session with boto3 session\n",
    "        sess = sagemaker.Session(boto_session=bt3)\n",
    "    else:\n",
    "        iam = boto3.client('iam')\n",
    "        sess = sagemaker.Session()\n",
    "    # get role arn\n",
    "    role = iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "\n",
    "\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3)\n",
      "Reusing dataset imdb (/Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3)\n",
      "Loading cached shuffled indices for dataset at /Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-80ccdcca361db0f6.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-40d4f3183282e2a2.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-82f8ca6d57daeab5.arrow\n",
      "Loading cached processed dataset at /Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-99758ae37c170387.arrow\n",
      "Loading cached processed dataset at /Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-c9273270e0bfd0cc.arrow\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "#helper tokenizer function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# load dataset\n",
    "train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])\n",
    "test_dataset = test_dataset.shuffle().select(range(10000)) # smaller the size for test dataset to 10k \n",
    "\n",
    "# sample a to small dataset for training\n",
    "train_dataset = train_dataset.shuffle().select(range(1000)) # smaller the size for test dataset to 10k \n",
    "test_dataset = test_dataset.shuffle().select(range(50)) # smaller the size for test dataset to 10k \n",
    "\n",
    "\n",
    "# tokenize dataset\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "\n",
    "# set format for pytorch\n",
    "train_dataset.rename_column_(\"label\", \"labels\")\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.rename_column_(\"label\", \"labels\")\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "\n",
    "# cach the dataset, so we can load it directly for training\n",
    "torch.save(train_dataset, 'train_dataset.pt')\n",
    "torch.save(test_dataset, 'test_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to sagemaker S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-558105141721/imdb/small/training/train_dataset.pt\n",
      "s3://sagemaker-eu-central-1-558105141721/imdb/small/test/test_dataset.pt\n"
     ]
    }
   ],
   "source": [
    "prefix = 'imdb/small'\n",
    "\n",
    "training_input_path  = sess.upload_data('train_dataset.pt', key_prefix=prefix+'/training')\n",
    "test_input_path      = sess.upload_data('test_dataset.pt', key_prefix=prefix+'/test')\n",
    "\n",
    "print(training_input_path)\n",
    "print(test_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local estimator for testing\n",
    "\n",
    "You run PyTorch training scripts on SageMaker by creating PyTorch Estimators. SageMaker training of your script is invoked when you call fit on a PyTorch Estimator. The following code sample shows how you train a custom PyTorch script `train.py`, passing in three hyperparameters (`epochs`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n",
    "\n",
    "in sagemaker you can test you training in a \"local-mode\" by setting your instance_type to `'local'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "pytorch_estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='src',\n",
    "                            base_job_name='huggingface',\n",
    "                            instance_type='local',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            framework_version='1.5.0',\n",
    "                            py_version='py3',\n",
    "                            hyperparameters = {'epochs': 1,\n",
    "                                               'train_batch_size': 32,\n",
    "                                               'model_name':'distilbert-base-uncased'\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-22 16:25:03 Starting - Starting the training job...\n",
      "2020-12-22 16:25:28 Starting - Launching requested ML instancesProfilerReport-1608654302: InProgress\n",
      "......\n",
      "2020-12-22 16:26:29 Starting - Preparing the instances for training......\n",
      "2020-12-22 16:27:29 Downloading - Downloading input data...\n",
      "2020-12-22 16:27:50 Training - Downloading the training image......\n",
      "2020-12-22 16:29:11 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-22 16:29:05,811 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-22 16:29:05,835 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-12-22 16:29:12,080 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-22 16:29:12,377 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting transformers\n",
      "  Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting datasets\n",
      "  Downloading datasets-1.1.3-py3-none-any.whl (153 kB)\u001b[0m\n",
      "\u001b[34mCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker[local] in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.72.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.11.13-cp36-cp36m-manylinux2014_x86_64.whl (723 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (4.46.0)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (2.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (0.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (20.4)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=0.17.1\n",
      "  Downloading pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.11.1-py36-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34mCollecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets->-r requirements.txt (line 3)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting xxhash\n",
      "  Downloading xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->-r requirements.txt (line 4)) (0.23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (3.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.14.12 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.16.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==0.1.4 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.4)\u001b[0m\n",
      "\u001b[34mCollecting docker-compose>=1.25.2; extra == \"local\"\n",
      "  Downloading docker_compose-1.27.4-py2.py3-none-any.whl (110 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML<6,>=5.3; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (5.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (0.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2020.6.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2020.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker[local]->-r requirements.txt (line 5)) (50.3.0.post20201006)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.20.0,>=1.19.3 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (1.19.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (0.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]->-r requirements.txt (line 5)) (3.3.1)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema<4,>=2.5.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting cached-property<2,>=1.2.0\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting distro<2,>=1.5.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting texttable<2,>=0.9.0\n",
      "  Downloading texttable-1.6.3-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting websocket-client<1,>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\u001b[0m\n",
      "\u001b[34mCollecting docopt<1,>=0.6.1\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-dotenv<1,>=0.13.0\n",
      "  Downloading python_dotenv-0.15.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker[ssh]<5,>=4.3.1\n",
      "  Downloading docker-4.4.0-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mCollecting dockerpty<1,>=0.4.1\n",
      "  Downloading dockerpty-0.4.1.tar.gz (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\u001b[0m\n",
      "\u001b[34mCollecting attrs>=17.4.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: paramiko>=2.4.2; extra == \"ssh\" in /opt/conda/lib/python3.6/site-packages (from docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from pynacl>=1.0.1->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.14.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.20)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn, sacremoses, docopt, dockerpty, pyrsistent\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=7392b6f0bb308516bf36d059ee5b2734cf2d66f04854185c29e3b04043d643a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "  Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=b8d2a8d1a3e3afb01b40971fc2f9e73e3f54950ff8450f81d53539be6907fe6d\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=48ae11819e898d246efea891e7e0fa91d2275452f699f87d3035b1dd7c2c18eb\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/2a/fa/4d7a888e69774d5e6e855d190a8a51b357d77cc05eb1c097c9\n",
      "  Building wheel for dockerpty (setup.py): started\n",
      "  Building wheel for dockerpty (setup.py): finished with status 'done'\n",
      "  Created wheel for dockerpty: filename=dockerpty-0.4.1-py3-none-any.whl size=16605 sha256=b2d9b23c2f8211d0fce303a7069e0db69374356a7ae13824324e4ac23c46624d\n",
      "  Stored in directory: /root/.cache/pip/wheels/61/8f/e3/247046231ee138b48be905e4a748d570630e1f3ec24632b00b\n",
      "  Building wheel for pyrsistent (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl size=112541 sha256=d3c5e303005b2c44253196e336eee30693c65caa9494b26e49f28bbcecaed103\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/13/19/294da8e11bce7e563afee51251b9fa878185e14f4b5caf00cb\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn sacremoses docopt dockerpty pyrsistent\u001b[0m\n",
      "\u001b[34mInstalling collected packages: regex, sacremoses, tokenizers, filelock, transformers, pyarrow, dill, multiprocess, xxhash, datasets, sklearn, pyrsistent, attrs, jsonschema, cached-property, distro, texttable, websocket-client, docopt, python-dotenv, docker, dockerpty, docker-compose\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-20.3.0 cached-property-1.5.2 datasets-1.1.3 dill-0.3.3 distro-1.5.0 docker-4.4.0 docker-compose-1.27.4 dockerpty-0.4.1 docopt-0.6.2 filelock-3.0.12 jsonschema-3.2.0 multiprocess-0.70.11.1 pyarrow-2.0.0 pyrsistent-0.17.3 python-dotenv-0.15.0 regex-2020.11.13 sacremoses-0.0.43 sklearn-0.0 texttable-1.6.3 tokenizers-0.9.4 transformers-4.1.1 websocket-client-0.57.0 xxhash-2.0.0\u001b[0m\n",
      "\u001b[34m2020-12-22 16:29:26,155 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_batch_size\": 32,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-2020-12-22-16-25-02-393\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-16-25-02-393/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-16-25-02-393/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-2020-12-22-16-25-02-393\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-16-25-02-393/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-12-22 16:29:34 Uploading - Uploading generated training model\n",
      "2020-12-22 16:29:34 Failed - Training job failed\n",
      "\u001b[34m2020-12-22 16:29:30,755 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\"\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 31, in <module>\n",
      "    train_dataset  = torch.load(os.path.join(args.training_dir, 'train_dataset.pt'))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/serialization.py\", line 585, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/serialization.py\", line 765, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_dataset.py\", line 414, in __setstate__\n",
      "    pa_table = reader._read_files([data_file])\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_reader.py\", line 167, in _read_files\n",
      "    pa_table: pa.Table = self._get_dataset_from_filename(f_dict)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_reader.py\", line 292, in _get_dataset_from_filename\n",
      "    mmap = pa.memory_map(filename)\n",
      "  File \"pyarrow/io.pxi\", line 782, in pyarrow.lib.memory_map\n",
      "  File \"pyarrow/io.pxi\", line 743, in pyarrow.lib.MemoryMappedFile._open\n",
      "  File \"pyarrow/error.pxi\", line 122, in pyarrow.lib.pyarrow_internal_check_status\n",
      "  File \"pyarrow/error.pxi\", line 97, in pyarrow.lib.check_status\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] Failed to open local file '/Users/philippschmid/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-99758ae37c170387.arrow'. Detail: [errno 2] No such file or directory\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job huggingface-2020-12-22-16-25-02-393: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\"\nTraceback (most recent call last):\n  File \"train.py\", line 31, in <module>\n    train_dataset  = torch.load(os.path.join(args.training_dir, 'train_dataset.pt'))\n  File \"/opt/conda/lib/python3.6/site-packages/torch/serialization.py\", line 585, in load\n    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/serialization.py\", line 765, in _legacy_load\n    result = unpickler.load()\n  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_dataset.py\", line 414, in __setstate__\n    pa_table = reader._read_files([data_file])\n  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_reader.py\", line 167, in _read_files\n    pa_table: pa.Table = self._get_dataset_from_filename(f_dict)\n  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_reader.py\", line 292, in _get_datas",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e5c8f8e04048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytorch_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3644\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3645\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3646\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3219\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FailureReason\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(No reason provided)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m             \u001b[0mjob_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus_key_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JobStatus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3222\u001b[0m                 message=\"Error for {job_type} {job_name}: {status}. Reason: {reason}\".format(\n\u001b[1;32m   3223\u001b[0m                     \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job huggingface-2020-12-22-16-25-02-393: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\"\nTraceback (most recent call last):\n  File \"train.py\", line 31, in <module>\n    train_dataset  = torch.load(os.path.join(args.training_dir, 'train_dataset.pt'))\n  File \"/opt/conda/lib/python3.6/site-packages/torch/serialization.py\", line 585, in load\n    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/serialization.py\", line 765, in _legacy_load\n    result = unpickler.load()\n  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_dataset.py\", line 414, in __setstate__\n    pa_table = reader._read_files([data_file])\n  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_reader.py\", line 167, in _read_files\n    pa_table: pa.Table = self._get_dataset_from_filename(f_dict)\n  File \"/opt/conda/lib/python3.6/site-packages/datasets/arrow_reader.py\", line 292, in _get_datas"
     ]
    }
   ],
   "source": [
    "pytorch_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Estimator\n",
    "\n",
    "You run PyTorch training scripts on SageMaker by creating PyTorch Estimators. SageMaker training of your script is invoked when you call fit on a PyTorch Estimator. The following code sample shows how you train a custom PyTorch script `train.py`, passing in three hyperparameters (`epochs`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "pytorch_estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='src',\n",
    "                            sagemaker_session=sess,\n",
    "#                            use_spot_instances=True,\n",
    "#                            max_wait=7200, # Seconds to wait for spot instances to become available\n",
    "                            base_job_name='huggingface',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            framework_version='1.6.0',\n",
    "                            py_version='py3',\n",
    "                            hyperparameters = {'epochs': 1,\n",
    "                                               'train_batch_size': 32,\n",
    "                                               'model_name':'distilbert-base-uncased'\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-22 16:13:10 Starting - Starting the training job...\n",
      "2020-12-22 16:13:35 Starting - Launching requested ML instancesProfilerReport-1608653589: InProgress\n",
      "......\n",
      "2020-12-22 16:14:36 Starting - Preparing the instances for training.........\n",
      "2020-12-22 16:16:13 Downloading - Downloading input data...\n",
      "2020-12-22 16:16:37 Training - Downloading the training image......\n",
      "2020-12-22 16:17:38 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-22 16:17:38,237 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-22 16:17:38,260 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-12-22 16:17:41,283 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-22 16:17:41,577 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting transformers\n",
      "  Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting datasets\n",
      "  Downloading datasets-1.1.3-py3-none-any.whl (153 kB)\u001b[0m\n",
      "\u001b[34mCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker[local] in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.72.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (2.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (20.4)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (4.46.0)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.11.13-cp36-cp36m-manylinux2014_x86_64.whl (723 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (0.7)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets->-r requirements.txt (line 3)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=0.17.1\n",
      "  Downloading pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.11.1-py36-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34mCollecting xxhash\n",
      "  Downloading xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->-r requirements.txt (line 4)) (0.23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==0.1.4 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (3.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.14.12 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.16.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML<6,>=5.3; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (5.3.1)\u001b[0m\n",
      "\u001b[34mCollecting docker-compose>=1.25.2; extra == \"local\"\n",
      "  Downloading docker_compose-1.27.4-py2.py3-none-any.whl (110 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2020.6.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from packaging->transformers->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (0.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2020.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]->-r requirements.txt (line 5)) (3.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker[local]->-r requirements.txt (line 5)) (50.3.0.post20201006)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.20.0,>=1.19.3 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (1.19.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (0.3.3)\u001b[0m\n",
      "\u001b[34mCollecting docker[ssh]<5,>=4.3.1\n",
      "  Downloading docker-4.4.0-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mCollecting distro<2,>=1.5.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting cached-property<2,>=1.2.0\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting texttable<2,>=0.9.0\n",
      "  Downloading texttable-1.6.3-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting docopt<1,>=0.6.1\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting dockerpty<1,>=0.4.1\n",
      "  Downloading dockerpty-0.4.1.tar.gz (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-dotenv<1,>=0.13.0\n",
      "  Downloading python_dotenv-0.15.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting websocket-client<1,>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema<4,>=2.5.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: paramiko>=2.4.2; extra == \"ssh\" in /opt/conda/lib/python3.6/site-packages (from docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\u001b[0m\n",
      "\u001b[34mCollecting attrs>=17.4.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from pynacl>=1.0.1->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.14.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.20)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn, sacremoses, docopt, dockerpty, pyrsistent\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=df13502d9c5ce67613312b322abf87c53ca8eef5c694d9c644def29f6c67dce9\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "  Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=895f2e0f18390c70a3b7e59ef80f23f0a5bf4575bafba54665dd254c6ae53440\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=3ba95fdf39a547e2380165c7658ecf1848ed4ee2481978163566a3b2947b8e3e\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/2a/fa/4d7a888e69774d5e6e855d190a8a51b357d77cc05eb1c097c9\n",
      "  Building wheel for dockerpty (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for dockerpty (setup.py): finished with status 'done'\n",
      "  Created wheel for dockerpty: filename=dockerpty-0.4.1-py3-none-any.whl size=16605 sha256=0f2e81ba32ea48e6ec6d9ddeae6d41f78c846cc4a8c5b1d1bbf158058e9ec644\n",
      "  Stored in directory: /root/.cache/pip/wheels/61/8f/e3/247046231ee138b48be905e4a748d570630e1f3ec24632b00b\n",
      "  Building wheel for pyrsistent (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl size=112538 sha256=717d475a728ad5f78463725028d97543301282779bad88663dcb5a510cc65298\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/13/19/294da8e11bce7e563afee51251b9fa878185e14f4b5caf00cb\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn sacremoses docopt dockerpty pyrsistent\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, filelock, regex, sacremoses, transformers, pyarrow, dill, multiprocess, xxhash, datasets, sklearn, websocket-client, docker, distro, cached-property, texttable, docopt, dockerpty, python-dotenv, pyrsistent, attrs, jsonschema, docker-compose\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-20.3.0 cached-property-1.5.2 datasets-1.1.3 dill-0.3.3 distro-1.5.0 docker-4.4.0 docker-compose-1.27.4 dockerpty-0.4.1 docopt-0.6.2 filelock-3.0.12 jsonschema-3.2.0 multiprocess-0.70.11.1 pyarrow-2.0.0 pyrsistent-0.17.3 python-dotenv-0.15.0 regex-2020.11.13 sacremoses-0.0.43 sklearn-0.0 texttable-1.6.3 tokenizers-0.9.4 transformers-4.1.1 websocket-client-0.57.0 xxhash-2.0.0\u001b[0m\n",
      "\u001b[34m2020-12-22 16:17:56,153 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_batch_size\": 32,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-2020-12-22-16-13-09-857\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-16-13-09-857/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-16-13-09-857/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-2020-12-22-16-13-09-857\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-16-13-09-857/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-12-22 16:18:01,995 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\"\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 24, in <module>\n",
      "    parser.add_argument('--training_dir', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
      "  File \"/opt/conda/lib/python3.6/os.py\", line 669, in __getitem__\n",
      "    raise KeyError(key) from None\u001b[0m\n",
      "\u001b[34mKeyError: 'SM_CHANNEL_TRAIN'\u001b[0m\n",
      "\n",
      "2020-12-22 16:18:18 Uploading - Uploading generated training model\n",
      "2020-12-22 16:18:18 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job huggingface-2020-12-22-16-13-09-857: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\"\nTraceback (most recent call last):\n  File \"train.py\", line 24, in <module>\n    parser.add_argument('--training_dir', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n  File \"/opt/conda/lib/python3.6/os.py\", line 669, in __getitem__\n    raise KeyError(key) from None\nKeyError: 'SM_CHANNEL_TRAIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-df48364deffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytorch_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3644\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3645\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3646\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3219\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FailureReason\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(No reason provided)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m             \u001b[0mjob_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus_key_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JobStatus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3222\u001b[0m                 message=\"Error for {job_type} {job_name}: {status}. Reason: {reason}\".format(\n\u001b[1;32m   3223\u001b[0m                     \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job huggingface-2020-12-22-16-13-09-857: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\"\nTraceback (most recent call last):\n  File \"train.py\", line 24, in <module>\n    parser.add_argument('--training_dir', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n  File \"/opt/conda/lib/python3.6/os.py\", line 669, in __getitem__\n    raise KeyError(key) from None\nKeyError: 'SM_CHANNEL_TRAIN'"
     ]
    }
   ],
   "source": [
    "pytorch_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
