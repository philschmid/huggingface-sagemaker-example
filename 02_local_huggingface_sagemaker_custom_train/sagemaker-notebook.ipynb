{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker example using `Trainer` class\n",
    "\n",
    "Each folder starting with `0X_..` contains an specific sagemaker example. Each example contains a jupyter notebooke `sagemaker-example.ipynb` and a `src/` folder. The `sagemaker-example` is a jupyter notebook which is used to train transformers and datasets on AWS Sagemaker. The `src/` folder contains the `train.py`, our training script and `requirements.txt` for additional dependencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Sagemaker Session with local AWS Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_profile_name='hf-sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# creates a boto3 session using the local profile we defined\n",
    "bt3 = boto3.session.Session(profile_name=local_profile_name)\n",
    "\n",
    "\n",
    "sess = sagemaker.Session(boto_session=bt3)\n",
    "\n",
    "# since we are using the sagemaker-sdk locally we cannot `get_execution_role` \n",
    "# role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From outside these notebooks, `get_execution_role()` will return an exception because it does not know what is the role name that SageMaker requires.\n",
    "\n",
    "To solve this issue, pass the IAM role name instead of using `get_execution_role()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = \"SageMakerRole\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_WARNING: This policy gives full S3 access to the container that is running in SageMaker. You can change this policy to a more restrictive one, or create your own policy._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name SageMakerRole already exists.\n"
     ]
    }
   ],
   "source": [
    "%%bash  -s \"$local_profile_name\" \"$role_name\" \n",
    "# This script creates a role named SageMakerRole\n",
    "# that can be used by SageMaker and has Full access to S3.\n",
    "\n",
    "ROLE_NAME=$2\n",
    "\n",
    "# WARNING: this policy gives full S3 access to container that\n",
    "# is running in SageMaker. You can change this policy to a more\n",
    "# restrictive one, or create your own policy.\n",
    "POLICY_S3=arn:aws:iam::aws:policy/AmazonS3FullAccess\n",
    "\n",
    "# Creates a AWS policy that allows the role to interact\n",
    "# with ANY S3 bucket\n",
    "cat <<EOF > /tmp/assume-role-policy-document.json\n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [{\n",
    "\t\t\"Effect\": \"Allow\",\n",
    "\t\t\"Principal\": {\n",
    "\t\t\t\"Service\": \"sagemaker.amazonaws.com\"\n",
    "\t\t},\n",
    "\t\t\"Action\": \"sts:AssumeRole\"\n",
    "\t}]\n",
    "}\n",
    "EOF\n",
    "\n",
    "# Creates the role\n",
    "aws iam create-role --profile $1  --role-name ${ROLE_NAME} --assume-role-policy-document file:///tmp/assume-role-policy-document.json\n",
    "\n",
    "# attaches the S3 full access policy to the role\n",
    "aws iam attach-role-policy --profile $1 --policy-arn ${POLICY_S3}  --role-name ${ROLE_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get create role arn \n",
    "iam = bt3.client('iam')\n",
    "role = iam.get_role(RoleName=role_name)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local estimator for testing\n",
    "\n",
    "You run PyTorch training scripts on SageMaker by creating PyTorch Estimators. SageMaker training of your script is invoked when you call fit on a PyTorch Estimator. The following code sample shows how you train a custom PyTorch script `train.py`, passing in three hyperparameters (`epochs`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n",
    "\n",
    "in sagemaker you can test you training in a \"local-mode\" by setting your instance_type to `'local'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "pytorch_estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='src',\n",
    "                            base_job_name='huggingface',\n",
    "                            instance_type='local',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            framework_version='1.5.0',\n",
    "                            py_version='py3',\n",
    "                            hyperparameters = {'epochs': 1,\n",
    "                                               'train_batch_size': 32,\n",
    "                                               'model_name':'distilbert-base-uncased',\n",
    "                                               'tokenizer':'distilbert-base-uncased'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpjxtziolz_algo-1-idsdf_1 ... \n",
      "\u001b[1BAttaching to tmpjxtziolz_algo-1-idsdf_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,208 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,220 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,237 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,241 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,622 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,623 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,623 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:34:39,623 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m /opt/conda/bin/python -m pip install . -r requirements.txt\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Processing /tmp/tmp4vsxx9_l/module_dir\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting numpy>=1.17.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting transformers\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting datasets\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading datasets-1.1.3-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting sklearn\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: sagemaker[local] in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.50.17)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting filelock\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting regex!=2019.12.17\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading regex-2020.11.13-cp36-cp36m-manylinux2014_x86_64.whl (723 kB)\n",
      "\u001b[K     |████████████████████████████████| 723 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (2.22.0)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting sacremoses\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (0.7)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (20.3)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting tokenizers==0.9.4\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (4.42.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting multiprocess\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading multiprocess-0.70.11.1-py36-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 3.1 MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets->-r requirements.txt (line 3)) (0.25.0)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting pyarrow>=0.17.1\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.7 MB 20.3 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting dill\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting xxhash\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->-r requirements.txt (line 4)) (0.21.2)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.5)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (3.11.3)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.2.2)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.6.0)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: boto3>=1.10.44 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.13.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: smdebug-rulesconfig==0.1.2 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.2)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.25.8)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting docker-compose>=1.25.2; extra == \"local\"\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading docker_compose-1.27.4-py2.py3-none-any.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hRequirement already satisfied: PyYAML<6,>=5.3; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (5.3.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2020.4.5.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2.8)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.0.4)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (1.14.0)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (7.1.2)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (0.14.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers->-r requirements.txt (line 2)) (2.4.7)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2019.3)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker[local]->-r requirements.txt (line 5)) (46.1.3.post20200330)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]->-r requirements.txt (line 5)) (3.1.0)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.44->sagemaker[local]->-r requirements.txt (line 5)) (0.9.5)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: botocore<1.17.0,>=1.16.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.44->sagemaker[local]->-r requirements.txt (line 5)) (1.16.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.44->sagemaker[local]->-r requirements.txt (line 5)) (0.3.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting docker[ssh]<5,>=4.3.1\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading docker-4.4.0-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting websocket-client<1,>=0.32.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting dockerpty<1,>=0.4.1\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading dockerpty-0.4.1.tar.gz (13 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting jsonschema<4,>=2.5.1\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting texttable<2,>=0.9.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading texttable-1.6.3-py2.py3-none-any.whl (10 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting cached-property<2,>=1.2.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting docopt<1,>=0.6.1\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting distro<2,>=1.5.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting python-dotenv<1,>=0.13.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading python_dotenv-0.15.0-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.17.0,>=1.16.1->boto3>=1.10.44->sagemaker[local]->-r requirements.txt (line 5)) (0.15.2)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: paramiko>=2.4.2; extra == \"ssh\" in /opt/conda/lib/python3.6/site-packages (from docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.7.1)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Collecting pyrsistent>=0.14.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading pyrsistent-0.17.3.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hCollecting attrs>=17.4.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25hRequirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (3.1.7)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.9.2)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.3.0)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: cffi>=1.1 in /opt/conda/lib/python3.6/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.14.0)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.20)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Building wheels for collected packages: sklearn, default-user-module-name, sacremoses, dockerpty, docopt, pyrsistent\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=7de074b0674e650ad9aed21631629e5dcc1c9bce3ef36bad636ea6ab25751e36\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Building wheel for default-user-module-name (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25h  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=7329 sha256=bafdae0b6b6c6c865d424fb69c2affa9def240cb0559633daa8ce574f6b6b4c2\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-_8hw7yi1/wheels/de/d7/cc/54de3c158c8dfde331319f6dfed600be797a7467a44e932ce0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=cb619057a87f4c09574c6440a51d1f9bd56ea6269db1bf5aa48a9029fbc461d8\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Building wheel for dockerpty (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25h  Created wheel for dockerpty: filename=dockerpty-0.4.1-py3-none-any.whl size=16604 sha256=230c6029eebd533dbd6c96a4981c1578e0f02f79d6f89f06bd25a2cb8e5a847e\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/61/8f/e3/247046231ee138b48be905e4a748d570630e1f3ec24632b00b\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=25a0b8f74f340e5bb5cb2d017d3fe0e50eb3c4a0615001825c6ef3084bec579a\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/3f/2a/fa/4d7a888e69774d5e6e855d190a8a51b357d77cc05eb1c097c9\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Building wheel for pyrsistent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[?25h  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl size=112549 sha256=3ae1e05f80a48fb6e6c765486457e7b504907deb7b364d593e3efe66129fffe9\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/34/13/19/294da8e11bce7e563afee51251b9fa878185e14f4b5caf00cb\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Successfully built sklearn default-user-module-name sacremoses dockerpty docopt pyrsistent\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Installing collected packages: numpy, filelock, regex, sacremoses, tokenizers, transformers, dill, multiprocess, pyarrow, xxhash, datasets, sklearn, default-user-module-name, websocket-client, docker, dockerpty, pyrsistent, attrs, jsonschema, texttable, cached-property, docopt, distro, python-dotenv, docker-compose\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   Attempting uninstall: numpy\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     Found existing installation: numpy 1.16.4\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     Uninstalling numpy-1.16.4:\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m       Successfully uninstalled numpy-1.16.4\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Successfully installed attrs-20.3.0 cached-property-1.5.2 datasets-1.1.3 default-user-module-name-1.0.0 dill-0.3.3 distro-1.5.0 docker-4.4.0 docker-compose-1.27.4 dockerpty-0.4.1 docopt-0.6.2 filelock-3.0.12 jsonschema-3.2.0 multiprocess-0.70.11.1 numpy-1.19.4 pyarrow-2.0.0 pyrsistent-0.17.3 python-dotenv-0.15.0 regex-2020.11.13 sacremoses-0.0.43 sklearn-0.0 texttable-1.6.3 tokenizers-0.9.4 transformers-4.1.1 websocket-client-0.57.0 xxhash-2.0.0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.1; however, version 20.3.3 is available.\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:35:12,599 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:35:12,634 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:35:12,662 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:35:12,677 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"current_host\": \"algo-1-idsdf\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m         \"algo-1-idsdf\"\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m         \"train_batch_size\": 32\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"job_name\": \"huggingface-2020-12-22-14-34-35-279\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"master_hostname\": \"algo-1-idsdf\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-eu-central-1-415465391280/huggingface-2020-12-22-14-34-35-279/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m         \"current_host\": \"algo-1-idsdf\",\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m             \"algo-1-idsdf\"\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_HOSTS=[\"algo-1-idsdf\"]\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_HPS={\"epochs\":1,\"train_batch_size\":32}\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-idsdf\",\"hosts\":[\"algo-1-idsdf\"]}\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_CURRENT_HOST=algo-1-idsdf\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-eu-central-1-415465391280/huggingface-2020-12-22-14-34-35-279/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-idsdf\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-idsdf\"],\"hyperparameters\":{\"epochs\":1,\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-2020-12-22-14-34-35-279\",\"log_level\":20,\"master_hostname\":\"algo-1-idsdf\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-415465391280/huggingface-2020-12-22-14-34-35-279/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-idsdf\",\"hosts\":[\"algo-1-idsdf\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1\",\"--train_batch_size\",\"32\"]\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m SM_HP_TRAIN_BATCH_SIZE=32\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m /opt/conda/bin/python train.py --epochs 1 --train_batch_size 32\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m \n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m 2020-12-22 14:35:12,713 sagemaker-containers ERROR    ExecuteUserScriptError:\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m Command \"/opt/conda/bin/python train.py --epochs 1 --train_batch_size 32\"\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m   File \"train.py\", line 106\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m             ^\n",
      "\u001b[36malgo-1-idsdf_1  |\u001b[0m IndentationError: expected an indented block\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mtmpjxtziolz_algo-1-idsdf_1 exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/private/var/folders/jj/dzns9hc55db1vmfsjvrh9n8m0000gp/T/tmpjxtziolz/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-df48364deffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytorch_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \"\"\"\n\u001b[1;32m   1417\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         self.model_artifacts = self.container.train(\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n",
      "\u001b[0;32m~/.anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/private/var/folders/jj/dzns9hc55db1vmfsjvrh9n8m0000gp/T/tmpjxtziolz/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "pytorch_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Estimator\n",
    "\n",
    "You run PyTorch training scripts on SageMaker by creating PyTorch Estimators. SageMaker training of your script is invoked when you call fit on a PyTorch Estimator. The following code sample shows how you train a custom PyTorch script `train.py`, passing in three hyperparameters (`epochs`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "pytorch_estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='src',\n",
    "                            sagemaker_session=sess,\n",
    "#                            use_spot_instances=True,\n",
    "#                            max_wait=7200, # Seconds to wait for spot instances to become available\n",
    "                            base_job_name='huggingface',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            framework_version='1.6.0',\n",
    "                            py_version='py3',\n",
    "                            hyperparameters = {'epochs': 1,\n",
    "                                               'train_batch_size': 32,\n",
    "                                               'model_name':'distilbert-base-uncased',\n",
    "                                               'tokenizer':'distilbert-base-uncased'\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-22 12:44:19 Starting - Starting the training job...\n",
      "2020-12-22 12:44:43 Starting - Launching requested ML instancesProfilerReport-1608641058: InProgress\n",
      "......\n",
      "2020-12-22 12:45:44 Starting - Preparing the instances for training......\n",
      "2020-12-22 12:46:46 Downloading - Downloading input data\n",
      "2020-12-22 12:46:46 Training - Downloading the training image........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-22 12:48:12,773 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-22 12:48:12,796 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\n",
      "2020-12-22 12:48:26 Training - Training image download completed. Training in progress.\u001b[34m2020-12-22 12:48:19,030 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-22 12:48:19,341 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting transformers\n",
      "  Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting datasets\n",
      "  Downloading datasets-1.1.3-py3-none-any.whl (153 kB)\u001b[0m\n",
      "\u001b[34mCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker[local] in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.72.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (4.46.0)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (0.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (20.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers->-r requirements.txt (line 2)) (2.24.0)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.11.13-cp36-cp36m-manylinux2014_x86_64.whl (723 kB)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting xxhash\n",
      "  Downloading xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=0.17.1\n",
      "  Downloading pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.11.1-py36-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets->-r requirements.txt (line 3)) (1.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->-r requirements.txt (line 4)) (0.23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.14.12 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.16.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (3.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==0.1.4 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (0.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.5.2)\u001b[0m\n",
      "\u001b[34mCollecting docker-compose>=1.25.2; extra == \"local\"\n",
      "  Downloading docker_compose-1.27.4-py2.py3-none-any.whl (110 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML<6,>=5.3; extra == \"local\" in /opt/conda/lib/python3.6/site-packages (from sagemaker[local]->-r requirements.txt (line 5)) (5.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (0.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2020.6.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2020.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]->-r requirements.txt (line 5)) (3.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.20.0,>=1.19.3 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (1.19.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (0.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker[local]->-r requirements.txt (line 5)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker[local]->-r requirements.txt (line 5)) (50.3.0.post20201006)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema<4,>=2.5.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting texttable<2,>=0.9.0\n",
      "  Downloading texttable-1.6.3-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-dotenv<1,>=0.13.0\n",
      "  Downloading python_dotenv-0.15.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting docopt<1,>=0.6.1\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting dockerpty<1,>=0.4.1\n",
      "  Downloading dockerpty-0.4.1.tar.gz (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker[ssh]<5,>=4.3.1\n",
      "  Downloading docker-4.4.0-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mCollecting distro<2,>=1.5.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting websocket-client<1,>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\u001b[0m\n",
      "\u001b[34mCollecting cached-property<2,>=1.2.0\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting attrs>=17.4.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: paramiko>=2.4.2; extra == \"ssh\" in /opt/conda/lib/python3.6/site-packages (from docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.5->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (1.14.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.5->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=4.3.1->docker-compose>=1.25.2; extra == \"local\"->sagemaker[local]->-r requirements.txt (line 5)) (2.20)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn, sacremoses, docopt, dockerpty, pyrsistent\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=890d39388f67f25ed5d8c8e46e6e068e7ec564732e47109cf5d5c0a2bbf45327\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "  Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=8803e4a4e2a28b81f8b2ae2c0183b56c11cff544fbc7d2f5b9735606d057c293\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=1013a99d6247d3ae3df5c4b7060ffab0e4436111604e537a12f2df5fa01ab264\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/2a/fa/4d7a888e69774d5e6e855d190a8a51b357d77cc05eb1c097c9\n",
      "  Building wheel for dockerpty (setup.py): started\n",
      "  Building wheel for dockerpty (setup.py): finished with status 'done'\n",
      "  Created wheel for dockerpty: filename=dockerpty-0.4.1-py3-none-any.whl size=16605 sha256=77a458bd0085a2b788e0473758e4dfd916f75fd4ab94d3f42fc2e3e02fd050e6\n",
      "  Stored in directory: /root/.cache/pip/wheels/61/8f/e3/247046231ee138b48be905e4a748d570630e1f3ec24632b00b\n",
      "  Building wheel for pyrsistent (setup.py): started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl size=112543 sha256=0aa01dea2ee568c49bcb1626bec8bdcb4f247eba3e15c405888ee69e6f2e5be8\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/13/19/294da8e11bce7e563afee51251b9fa878185e14f4b5caf00cb\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn sacremoses docopt dockerpty pyrsistent\u001b[0m\n",
      "\u001b[34mInstalling collected packages: regex, sacremoses, filelock, tokenizers, transformers, xxhash, pyarrow, dill, multiprocess, datasets, sklearn, attrs, pyrsistent, jsonschema, texttable, python-dotenv, docopt, dockerpty, websocket-client, docker, distro, cached-property, docker-compose\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-20.3.0 cached-property-1.5.2 datasets-1.1.3 dill-0.3.3 distro-1.5.0 docker-4.4.0 docker-compose-1.27.4 dockerpty-0.4.1 docopt-0.6.2 filelock-3.0.12 jsonschema-3.2.0 multiprocess-0.70.11.1 pyarrow-2.0.0 pyrsistent-0.17.3 python-dotenv-0.15.0 regex-2020.11.13 sacremoses-0.0.43 sklearn-0.0 texttable-1.6.3 tokenizers-0.9.4 transformers-4.1.1 websocket-client-0.57.0 xxhash-2.0.0\u001b[0m\n",
      "\u001b[34m2020-12-22 12:48:32,502 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_batch_size\": 32,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"epochs\": 1,\n",
      "        \"tokenizer\": \"distilbert-base-uncased\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-2020-12-22-12-44-18-925\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-12-44-18-925/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"tokenizer\":\"distilbert-base-uncased\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-12-44-18-925/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"tokenizer\":\"distilbert-base-uncased\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-2020-12-22-12-44-18-925\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-558105141721/huggingface-2020-12-22-12-44-18-925/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--tokenizer\",\"distilbert-base-uncased\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_TOKENIZER=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --tokenizer distilbert-base-uncased --train_batch_size 32\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.06 MiB, post-processed: Unknown size, total: 207.28 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3...\u001b[0m\n",
      "\u001b[34mDataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:22,867 - filelock - INFO - Lock 140376442949416 acquired on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:23,152 - filelock - INFO - Lock 140376442949416 released on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:23,436 - filelock - INFO - Lock 140378852995872 acquired on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:28,748 - filelock - INFO - Lock 140378852995872 released on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:31,626 - filelock - INFO - Lock 140376444523352 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:32,259 - filelock - INFO - Lock 140376444523352 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:32,547 - filelock - INFO - Lock 140376444525144 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:33,278 - filelock - INFO - Lock 140376444525144 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:34,188 - __main__ - INFO - Sample 704 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 7929, 1010, 1045, 2031, 3427, 1996, 2434, 2413, 2544, 1012, 2021, 1045, 2064, 1005, 1056, 5674, 2023, 2108, 2488, 2007, 4942, 27430, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2035, 1045, 2031, 2000, 2360, 2008, 2023, 2003, 1996, 2087, 11771, 3185, 1045, 2031, 2464, 1999, 1037, 2146, 2051, 1012, 2045, 2024, 2471, 2053, 2417, 21564, 2075, 11647, 2000, 2023, 2143, 1012, 2008, 1005, 1055, 2339, 1045, 2064, 1005, 1056, 3305, 2035, 1996, 3893, 4391, 1012, 2009, 2453, 2022, 12689, 1999, 1037, 3168, 2021, 2070, 2613, 3441, 2024, 2190, 2187, 19662, 6392, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2788, 2066, 4030, 13823, 5691, 2004, 2146, 2004, 2009, 4240, 1996, 3800, 1997, 1996, 3185, 1012, 16985, 23829, 1005, 1055, 5943, 2483, 2003, 5186, 4030, 13823, 2021, 2009, 4473, 17174, 13102, 18491, 1998, 4520, 1996, 6888, 1997, 1996, 2143, 2005, 2742, 1012, 2021, 1999, 2023, 2553, 1010, 1996, 3185, 2003, 2074, 6406, 2007, 2568, 3238, 13764, 8649, 2008, 6133, 2000, 2425, 2149, 2210, 2055, 1996, 3494, 1012, 3904, 1997, 2029, 1045, 2071, 6709, 2007, 2030, 2729, 2005, 1012, 1999, 1037, 2843, 1997, 1996, 5019, 1045, 2179, 2870, 3241, 1024, 1000, 2043, 2024, 2027, 2183, 2000, 3844, 2039, 1000, 1029, 1996, 3772, 2001, 3492, 2919, 1012, 2025, 1999, 2019, 2058, 18908, 2075, 5793, 2785, 1997, 2126, 1012, 2021, 2009, 3849, 3904, 1997, 1996, 5889, 8725, 2055, 2037, 3494, 1998, 2027, 2035, 2246, 2066, 2027, 2359, 2000, 2022, 6974, 1999, 2087, 1997, 1996, 5019, 1012, 2023, 2453, 2022, 2349, 2000, 1996, 4895, 7076, 21649, 13764, 8649, 2027, 2020, 2445, 1012, 2036, 1996, 2878, 4834, 1997, 1996, 3185, 2371, 3243, 6228, 1012, 2183, 2013, 2028, 3496, 2000, 1996, 2279, 1012, 2009, 3849, 2023, 3185, 2001, 2074, 2517, 1006, 6649, 1007, 2021, 2196, 2856, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2023, 2003, 2028, 1997, 1996, 2261, 3152, 2008, 1045, 2064, 2360, 7013, 2053, 6832, 3433, 2013, 2151, 1997, 1996, 5019, 1012, 2053, 23873, 1010, 2053, 3571, 1010, 2053, 11162, 1010, 2053, 14038, 1010, 2053, 17174, 13102, 18491, 1010, 2053, 7789, 20858, 1010, 2053, 3037, 2054, 2061, 2412, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1037, 3819, 2742, 1997, 2054, 1045, 2655, 2019, 3424, 1011, 3185, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, 'text': 'OK, I have watched the original French version. But I can\\'t imagine this being better with subtitles.<br /><br />All I have to say that this is the most boring movie I have seen in a long time. There are almost no redeeming qualities to this film. That\\'s why I can\\'t understand all the positive reviews. It might be realistic in a sense but some real stories are best left untold.<br /><br />I usually like slow paced movies as long as it serves the purpose of the movie. Tarkovsky\\'s Solaris is extremely slow paced but it allows introspection and sets the mood of the film for example. But in this case, the movie is just filed with mindless dialog that manage to tell us little about the characters. None of which I could identify with or care for. In a lot of the scenes I found myself thinking: \"When are they going to shut up\"? The acting was pretty bad. Not in an overacting obvious kind of way. But It seems none of the actors cared about their characters and they all looked like they wanted to be elsewhere in most of the scenes. This might be due to the uninspired dialog they were given. Also the whole flow of the movie felt quite mechanical. Going from one scene to the next. It seems this movie was just written (badly) but never directed.<br /><br />This is one of the few films that I can say generated no emotional response from any of the scenes. No suspense, no fear, no anticipation, no sorrow, no introspection, no intellectual stimulation, no interest what so ever.<br /><br />A perfect example of what I call an anti-movie.'}.\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:34,189 - __main__ - INFO - Sample 610 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [101, 1000, 1999, 2258, 3918, 1010, 1996, 2118, 1997, 3190, 3530, 2000, 5452, 12098, 7446, 2638, 2120, 5911, 1010, 2007, 2019, 2523, 1997, 13608, 11795, 5534, 5378, 2000, 10460, 1996, 2470, 1012, 12098, 7446, 2638, 8558, 2150, 1996, 2034, 1000, 2120, 1000, 5911, 1012, 2009, 2106, 2025, 1010, 2174, 1010, 3961, 2012, 2049, 2434, 3295, 1999, 1996, 12098, 7446, 2638, 3224, 1012, 1999, 4006, 1010, 2009, 2333, 8736, 2225, 2013, 1996, 1000, 27370, 2103, 1000, 2000, 1037, 2047, 2609, 2006, 4307, 16439, 1012, 2043, 17348, 11417, 11144, 4716, 12098, 7446, 2638, 1005, 1055, 2472, 1010, 4787, 1062, 23111, 1010, 1999, 4006, 1010, 2002, 2356, 2032, 2054, 2785, 1997, 13308, 2001, 2000, 2022, 2328, 2012, 1996, 2047, 2609, 1012, 2043, 1062, 23111, 2649, 1037, 3082, 1011, 2300, 13308, 4082, 2012, 2028, 1011, 7891, 1996, 2373, 1997, 1996, 4475, 5604, 13308, 2104, 2640, 2012, 6116, 5526, 1010, 11417, 11144, 19700, 2009, 2052, 2022, 16325, 2065, 1062, 23111, 2165, 1996, 6116, 5526, 2640, 1998, 3498, 1996, 4475, 5604, 13308, 2012, 2028, 1011, 7891, 3977, 1012, 1996, 8257, 4928, 4895, 18447, 4765, 19301, 2135, 12168, 2594, 1012, 1000, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 1055, 1011, 2753, 3269, 2109, 23849, 2000, 3584, 1996, 28846, 2015, 1999, 5190, 1997, 4206, 7753, 1012, 2009, 2001, 2328, 2279, 2000, 1996, 1047, 1011, 2423, 2373, 3269, 1010, 2029, 3024, 1996, 4072, 5492, 1012, 2172, 2625, 8114, 2084, 1047, 1011, 2423, 1010, 1996, 1055, 1011, 2753, 3269, 2001, 7950, 2091, 2044, 1996, 2162, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 4986, 2008, 1996, 9593, 2943, 3222, 2470, 2565, 2453, 2468, 2205, 3834, 1010, 13451, 11638, 8865, 2511, 1037, 2837, 1997, 3919, 24205, 1010, 1998, 2076, 1037, 2281, 3942, 2000, 6116, 5526, 1010, 2002, 6936, 2007, 5215, 2415, 1010, 3208, 1997, 2482, 17062, 2063, 1004, 6351, 1010, 1037, 7506, 1997, 2586, 2482, 17062, 2063, 3840, 2012, 6116, 5526, 1010, 1996, 6061, 1997, 1996, 2194, 10262, 2968, 1997, 1996, 5911, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 3159, 2888, 1006, 1997, 10724, 1007, 7194, 1999, 2899, 1998, 5873, 1996, 2446, 8408, 1006, 5774, 1007, 1012, 15329, 1010, 2007, 3159, 2888, 1997, 10724, 2429, 2000, 1996, 6481, 1997, 2671, 1998, 2049, 16796, 2037, 2020, 2525, 5936, 2007, 1996, 5097, 1997, 2047, 2671, 2007, 2510, 5097, 1012, 1996, 7570, 10222, 6844, 10820, 2078, 1006, 5774, 1013, 2462, 1007, 1010, 1000, 15676, 9070, 1005, 1055, 21459, 12187, 2012, 1996, 20460, 2358, 1012, 10356, 1010, 2047, 2259, 1012, 2579, 2012, 1996, 6635, 2617, 1997, 3159, 2888, 1005, 1055, 5508, 1010, 1998, 1996, 6274, 1997, 1996, 2548, 3115, 1012, 1000, 2065, 16664, 2354, 1997, 2122, 4072, 29361, 2000, 6926, 7574, 2059, 2054, 2001, 1996, 13185, 1997, 1996, 8309, 1059, 9148, 1998, 25755, 1012, 1996, 3737, 1997, 2968, 2491, 1045, 3653, 23545, 1029, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2947, 1010, 2106, 1996, 25144, 1997, 3169, 10577, 6951, 2005, 1037, 2510, 3260, 1010, 2030, 1037, 2449, 2933, 1010, 2241, 2006, 1996, 3036, 6481, 1997, 5911, 2968, 1029, 2138, 10743, 2037, 2020, 2053, 8643, 1010, 1998, 1996, 3924, 2040, 2020, 102], 'label': 1, 'text': '\"In April 1946, the University of Chicago agreed to operate Argonne National Laboratory, with an association of Midwestern universities offering to sponsor the research. Argonne thereby became the first \"national\" laboratory. It did not, however, remain at its original location in the Argonne forest. In 1947, it moved farther west from the \"Windy City\" to a new site on Illinois farmland. When Alvin Weinberg visited Argonne\\'s director, Walter Zinn, in 1947, he asked him what kind of reactor was to be built at the new site. When Zinn described a heavy-water reactor operating at one-tenth the power of the Materials Testing Reactor under design at Oak Ridge, Weinberg joked it would be simpler if Zinn took the Oak Ridge design and operated the Materials Testing Reactor at one-tenth capacity. The joke proved unintentionally prophetic.\"<br /><br />The S-50 plant used convection to separate the isotopes in thousands of tall columns. It was built next to the K-25 power plant, which provided the necessary steam. Much less efficient than K-25, the S-50 plant was torn down after the war.<br /><br />Concerned that the Atomic Energy Commission research program might become too academic, Lilienthal established a committee of industrial advisers, and during a November visit to Oak Ridge, he discussed with Clark Center, manager of Carbide & Carbon, a subsidiary of Union Carbide Corporation at Oak Ridge, the possibility of the company assuming management of the Laboratory.<br /><br />Prince Henry (of Prussia) Arriving in Washington and Visiting the German Embassy (1902). Evidently, with Prince Henry of Prussia according to the principles of science and its dangers their were already concerns with the applications of new science with military applications. The Hohenzollern (1902/II), \"Kaiser Wilhelm\\'s splendid yacht at the 34th St. Pier, New York. Taken at the exact moment of Prince Henry\\'s arrival, and the raising of the royal standard.\" If Royalty knew of these necessary precautions to citizen welfare then what was the necessity of the warfare WWI and WWII. The quality of management control I presume?<br /><br />Thus, did the commandos of Operation Swallow volunteer for a military mission, or a business plan, based on the security principles of Laboratory management? Because supposedly their were no survivors, and the ones who were caught in Europe ordered to be executed. Of the 400 man commando team the survivors who were captured were executed under orders of the German Army against subversion, and espionage acts of the State of Germany. <br /><br />The Führer No. 003830/42 g. Kdos. OKW/WFSt, Führer HQ, 18 Oct. 1942, (signed) Adolph Hitler; Translation of Document no. 498-PS, Office of U.S. Chief of Counsel, certified true copy Kipp Major, declassified DOD 5200.30 March 23, 1983, reproduced at the U.S. National Archives.<br /><br />The OSS Society® 6723 Whittier Ave., 200 McLean, VA 22101'}.\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:34,190 - __main__ - INFO - Sample 482 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [101, 1045, 3427, 12665, 24375, 2015, 2138, 1997, 1996, 12610, 4193, 2009, 1012, 2092, 1010, 1045, 2064, 1005, 1056, 5674, 3087, 16663, 2023, 3185, 2138, 2009, 1005, 1055, 2074, 2919, 1010, 2919, 1010, 2919, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 1005, 1055, 5793, 2008, 9444, 2081, 2023, 3185, 2987, 1005, 1056, 2113, 1037, 2309, 2518, 2055, 5469, 1012, 1996, 2878, 2466, 2003, 2019, 7736, 3510, 1997, 2048, 11541, 1024, 2895, 3185, 1006, 4409, 1998, 12290, 1007, 1998, 5469, 1006, 2542, 12665, 24375, 2015, 1007, 1012, 2043, 1996, 12290, 2024, 2730, 2028, 2011, 2028, 2011, 1996, 13433, 4801, 2559, 12665, 24375, 2015, 1010, 1996, 2048, 11541, 8073, 17542, 2169, 2060, 2041, 2138, 1010, 2034, 1010, 2027, 1005, 2128, 12290, 1998, 2040, 14977, 2055, 12290, 1010, 1998, 2117, 1010, 2138, 2027, 1005, 2128, 5236, 12290, 2000, 9573, 999, 2383, 11798, 12665, 24375, 2015, 2175, 2044, 2068, 2074, 2987, 1005, 1056, 2147, 2182, 1012, 2073, 1005, 1055, 1996, 5469, 1999, 2008, 1029, 1045, 2359, 1996, 12290, 2000, 3280, 9202, 1010, 9145, 6677, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2021, 1996, 2466, 2003, 2061, 6649, 3833, 2008, 2023, 3510, 1997, 11541, 1010, 2029, 2071, 2031, 2042, 2434, 2065, 5047, 2092, 1010, 2196, 21500, 2015, 1012, 2057, 1005, 2128, 3432, 2187, 2007, 2003, 1037, 9129, 1997, 3565, 9742, 12290, 1998, 1037, 9129, 1997, 12665, 24375, 2015, 1010, 2029, 2024, 1000, 4142, 1000, 2005, 3649, 13109, 5714, 6508, 3114, 1996, 16587, 2245, 2039, 1012, 2437, 2477, 2130, 4788, 2003, 1996, 2755, 2008, 1996, 16434, 2003, 6659, 1006, 2694, 2066, 1007, 1998, 1010, 4788, 10048, 1997, 2035, 1010, 2878, 9129, 2229, 1997, 1996, 7982, 2024, 2409, 2006, 6568, 1010, 1998, 2057, 10843, 2963, 27118, 2638, 7982, 5287, 2058, 23657, 4871, 2004, 2065, 2057, 1005, 2128, 3666, 2070, 4066, 1997, 2557, 2265, 1012, 2023, 2112, 2001, 2428, 2919, 1012, 1996, 2472, 2323, 2031, 2042, 2915, 2006, 1996, 3962, 2005, 2746, 2039, 2007, 2107, 1037, 5236, 2801, 999, 1045, 2064, 1005, 1056, 2425, 2017, 2129, 15703, 2008, 2001, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2004, 1045, 1005, 2310, 2525, 3855, 1010, 1996, 12290, 1999, 12665, 24375, 2015, 2024, 29350, 5236, 1012, 2005, 6013, 1010, 2043, 2619, 3402, 3065, 2039, 1010, 9535, 3064, 1998, 3561, 2007, 2769, 1998, 13137, 1006, 15624, 1010, 13137, 1007, 1999, 2010, 4121, 2330, 6357, 1010, 1996, 2500, 3198, 1000, 2054, 4319, 2003, 2002, 2006, 1029, 1000, 2044, 2027, 5607, 6197, 1997, 10432, 1999, 2032, 1010, 4039, 2000, 3102, 2032, 1006, 2002, 1005, 1055, 2042, 1000, 11798, 10451, 1000, 2011, 1996, 12665, 24375, 2015, 1012, 2123, 1005, 1056, 3198, 1012, 1012, 1012, 1007, 1012, 2131, 1037, 13847, 9789, 1010, 22822, 5644, 1012, 1045, 1005, 2310, 2196, 2464, 2107, 5236, 2111, 1999, 1037, 3185, 1012, 1998, 2059, 2045, 1005, 1055, 1996, 2611, 1012, 1045, 6257, 2028, 1997, 1996, 12665, 24375, 2015, 2018, 2730, 2014, 2855, 2138, 2016, 2001, 1037, 3255, 1999, 1996, 10007, 1012, 2043, 2016, 4858, 2014, 2269, 26304, 2000, 1037, 12665, 24375, 1000, 2892, 1000, 1010, 2016, 2941, 7499, 2015, 1996, 12290, 1999, 2019, 16436, 3496, 102], 'label': 0, 'text': 'I watched SCARECROWS because of the buzz surrounding it. Well, I can\\'t imagine anyone liking this movie because it\\'s just bad, bad, bad.<br /><br />It\\'s obvious that whoever made this movie doesn\\'t know a single thing about horror. The whole story is an unsuccessful marriage of two genres: action movie (guns and criminals) and horror (living scarecrows). When the criminals are killed one by one by the poky looking scarecrows, the two genres automatically cancel each other out because, first, they\\'re criminals and who cares about criminals, and second, because they\\'re stupid criminals to boot! Having zombie scarecrows go after them just doesn\\'t work here. Where\\'s the horror in that? I wanted the criminals to die horrible, painful deaths.<br /><br />But the story is so badly constructed that this marriage of genres, which could have been original if handle well, NEVER gels. We\\'re simply left with is a bunch of super dense criminals and a bunch of scarecrows, which are \"alive\" for whatever flimsy reason the filmmakers thought up. Making things even worse is the fact that the cinematography is terrible (TV like) and, worse offense of all, whole bunches of the dialogue are told on CBs, and we continuously hear inane dialogue spoken over disconnected images as if we\\'re watching some sort of Radio show. This part was really BAD. The director should have been shot on the spot for coming up with such a stupid idea! I can\\'t tell you how annoying that was.<br /><br />As I\\'ve already mentioned, the criminals in SCARECROWS are amazingly stupid. For instance, when someone suddenly shows up, gutted and filled with money and straw (yep, straw) in his huge open wound, the others ask \"What drug is he on?\" after they shoot tons of bullets in him, unable to kill him (he\\'s been \"zombiefied\" by the scarecrows. Don\\'t ask...). Get a freaking clue, morons. I\\'ve never seen such stupid people in a movie. And then there\\'s the girl. I wished one of the scarecrows had killed her quickly because she was a pain in the butt. When she finds her father nailed to a scarecrow \"cross\", she actually blames the criminals in an embarrassing scene (bad acting), even though the criminals couldn\\'t have done it. What a dimwit she was! But the scarecrows are the biggest weakness in this very weak flick. They\\'re not scary. Nothing much is explained about them. They\\'re just a plot device in this plot device filled movie.<br /><br />Mr Wesley, filming the face of a scarecrow for 30 seconds nonstop doesn\\'t elicit anything but sheer boredom. And that scene with the talking head in the fridge. Thanks for the laughter.<br /><br />All in all, this had to be one of the worst movies I\\'ve seen recently (and I\\'ve seen a lot of movies these days!) Between the equally woeful SILO KILLER or SCARECROWS, I\\'d rather watcher SILO KILLER again. Yep, SCARECROWS is that bad.'}.\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:37.423 algo-1:67 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:37.423 algo-1:67 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:37.423 algo-1:67 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:37.423 algo-1:67 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:37.448 algo-1:67 INFO hook.py:398] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:37.448 algo-1:67 INFO hook.py:459] Hook is writing from the hook with pid: 67\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:38.386 algo-1:67 WARNING hook.py:944] var is not Tensor or list or tuple of Tensors, module_name:distilbert.transformer BaseModelOutput\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:38.386 algo-1:67 WARNING hook.py:944] var is not Tensor or list or tuple of Tensors, module_name:distilbert BaseModelOutput\u001b[0m\n",
      "\u001b[34m[2020-12-22 12:49:38.463 algo-1:67 WARNING hook.py:944] var is not Tensor or list or tuple of Tensors, module_name:DistilBertForSequenceClassification SequenceClassifierOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-12-22 12:49:59 Uploading - Uploading generated training model\u001b[34m{'eval_loss': 0.6840440630912781, 'eval_accuracy': 0.72, 'eval_f1': 0.5625000000000001, 'eval_precision': 0.75, 'eval_recall': 0.45, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m2020-12-22 12:49:57,627 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-22 12:50:48 Completed - Training job completed\n",
      "Training seconds: 256\n",
      "Billable seconds: 256\n"
     ]
    }
   ],
   "source": [
    "pytorch_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
